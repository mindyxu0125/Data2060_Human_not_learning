{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7917ab9",
   "metadata": {},
   "source": [
    "## DATA2060 Final Project\n",
    "\n",
    "Model: **CART for classification**\n",
    "\n",
    "Team Members:\n",
    "- Muxin Fu\n",
    "- Yixiao Zhang\n",
    "- Jingming Xu\n",
    "- Mingrui Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897fd31",
   "metadata": {},
   "source": [
    "### 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d81ff2",
   "metadata": {},
   "source": [
    "### 1. Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc5ddd",
   "metadata": {},
   "source": [
    "### 2. Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab2653",
   "metadata": {},
   "source": [
    "In the classification setting, losses are the **mearuses of impurity**.  CART minimizes impruity and the loss is defined per split. Generally speaking, **Gini** and **Entropy** are good measures.\n",
    "\n",
    "To compute Loss, we need: \n",
    "* Impurity measure, \n",
    "* Split loss based on choosen impurity measure.\n",
    "\n",
    "In the scikit-learn, this is determined by the parameter **criterion**: *{“gini”, “entropy”, “log_loss”}, default=”gini”* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e29c6",
   "metadata": {},
   "source": [
    "#### 2.1 **Impurity Function**\n",
    "\n",
    "For a $K$-class classification problem, consider node $i$ containing a subset of samples\n",
    "\n",
    "$$S_i = \\{(x_j, y_j)\\}_{j \\in \\mathcal{I}_i}, \\qquad N_i = |S_i|.$$\n",
    "\n",
    "The number of samples in node $i$ that belong to class $k$ is\n",
    "\n",
    "$$n_{i,k} = \\sum_{j \\in \\mathcal{I}_i} \\mathbf{1}(y_j = k).$$\n",
    "\n",
    "The class proportion of class $k$ in node $i$ is\n",
    "\n",
    "$$p_{i,k} = \\frac{n_{i,k}}{N_i}, \\qquad k = 1, \\dots, K.$$\n",
    "$$\\sum_{k=1}^K p_{i,k} = 1,\\text{and  } p_{i,k} \\ge 0 \\quad \\text{for } k = 1, \\dots, K.$$\n",
    "\n",
    "##### 2.1.1 **Gini**\n",
    "\n",
    "\n",
    "- The Gini impurity of node $i$ is:   \n",
    "$$G_i = 1 - \\sum_{k=1}^K p_{i,k}^2.$$\n",
    "\n",
    "##### 2.1.2 **Entropy**\n",
    "\n",
    "- The entropy impurity of node $i$ is\n",
    "$$H_i = - \\sum_{k=1}^K p_{i,k} \\log p_{i,k},$$\n",
    "\n",
    "- And we assume $0 \\log 0 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad0f55",
   "metadata": {},
   "source": [
    "#### 2.2 **Split Loss**\n",
    "\n",
    "Given a candidate split $\\theta$ applied at node $i$, the dataset $S_i$ is partitioned into a left subset $S_i^{\\text{left}}(\\theta)$ and a right subset $S_i^{\\text{right}}(\\theta)$:\n",
    "\n",
    "$$\n",
    "S_i^{\\text{left}}(\\theta) = \\{(x_j, y_j) \\in S_i \\mid x_{j, f} \\le t\\},\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_i^{\\text{right}}(\\theta) = S_i \\setminus S_i^{\\text{left}}(\\theta),\n",
    "$$\n",
    "\n",
    "where $\\theta = (f, t)$ denotes the split feature index $f$ and the threshold value $t$.\n",
    "\n",
    "Let the number of samples in the left and right subsets be\n",
    "\n",
    "$$\n",
    "N_i^{\\text{left}} = |S_i^{\\text{left}}(\\theta)|, \\qquad \n",
    "N_i^{\\text{right}} = |S_i^{\\text{right}}(\\theta)|.\n",
    "$$\n",
    "\n",
    "Their corresponding class proportions are computed in the same way as in Section 2.1.\n",
    "\n",
    "\n",
    "##### 2.2.1 **Weighted Child Impurity**\n",
    "\n",
    "Given an impurity function $C(\\cdot)$ (e.g., Gini or entropy), the **split loss** at node $i$ for candidate split $\\theta$ is defined as the weighted sum of the left and right child impurities:\n",
    "\n",
    "$$\n",
    "L(S_i, \\theta) \n",
    "= \n",
    "\\frac{N_i^{\\text{left}}}{N_i} \n",
    "\\, C\\!\\left(S_i^{\\text{left}}(\\theta)\\right)\n",
    "\\;+\\;\n",
    "\\frac{N_i^{\\text{right}}}{N_i}\n",
    "\\, C\\!\\left(S_i^{\\text{right}}(\\theta)\\right).\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $C\\!\\left(S_i^{\\text{left}}(\\theta)\\right)$ is the impurity (Gini or entropy) of the left child node.\n",
    "- $C\\!\\left(S_i^{\\text{right}}(\\theta)\\right)$ is the impurity of the right child node.\n",
    "\n",
    "\n",
    "##### 2.2.2 **Optimal Split Selection**\n",
    "\n",
    "The optimal split parameter is chosen by minimizing the split loss:\n",
    "\n",
    "$$\n",
    "\\theta^{*} = \\arg\\min_{\\theta} \\; L(S_i, \\theta).\n",
    "$$\n",
    "\n",
    "And this will be futher explained in the next part, Optimizer on how to actually implement it.\n",
    "\n",
    "- ***Reference***: scikit-learn mathematical formulation https://scikit-learn.org/stable/modules/tree.html#tree-mathematical-formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eed380",
   "metadata": {},
   "source": [
    "### 3. Optimizer"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
