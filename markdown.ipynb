{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7917ab9",
   "metadata": {},
   "source": [
    "## DATA2060 Final Project\n",
    "\n",
    "Model: **CART for classification**\n",
    "\n",
    "Team Members:\n",
    "- Muxin Fu\n",
    "- Yixiao Zhang\n",
    "- Jingming Xu\n",
    "- Mingrui Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897fd31",
   "metadata": {},
   "source": [
    "### 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d81ff2",
   "metadata": {},
   "source": [
    "### 1. Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc5ddd",
   "metadata": {},
   "source": [
    "### 2. Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab2653",
   "metadata": {},
   "source": [
    "In the classification setting, losses are the **mearuses of impurity**.  CART minimizes impruity and the loss is defined per split. Generally speaking, **Gini** and **Entropy** are good measures.\n",
    "\n",
    "To compute Loss, we need: \n",
    "* Impurity measure, \n",
    "* Split loss based on choosen impurity measure.\n",
    "\n",
    "In the scikit-learn, this is determined by the parameter **criterion**: *{“gini”, “entropy”, “log_loss”}, default=”gini”* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e29c6",
   "metadata": {},
   "source": [
    "#### 2.1 **Impurity Function**\n",
    "\n",
    "For a $K$-class classification problem, consider node $i$ containing a subset of samples\n",
    "\n",
    "$$S_i = \\{(x_j, y_j)\\}_{j \\in \\mathcal{I}_i}, \\qquad N_i = |S_i|.$$\n",
    "\n",
    "The number of samples in node $i$ that belong to class $k$ is\n",
    "\n",
    "$$n_{i,k} = \\sum_{j \\in \\mathcal{I}_i} \\mathbf{1}(y_j = k).$$\n",
    "\n",
    "The class proportion of class $k$ in node $i$ is\n",
    "\n",
    "$$p_{i,k} = \\frac{n_{i,k}}{N_i}, \\qquad k = 1, \\dots, K.$$\n",
    "$$\\sum_{k=1}^K p_{i,k} = 1,\\text{and  } p_{i,k} \\ge 0 \\quad \\text{for } k = 1, \\dots, K.$$\n",
    "\n",
    "##### 2.1.1 **Gini**\n",
    "\n",
    "\n",
    "- The Gini impurity of node $i$ is:   \n",
    "$$G_i = 1 - \\sum_{k=1}^K p_{i,k}^2.$$\n",
    "\n",
    "##### 2.1.2 **Entropy**\n",
    "\n",
    "- The entropy impurity of node $i$ is\n",
    "$$H_i = - \\sum_{k=1}^K p_{i,k} \\log p_{i,k},$$\n",
    "\n",
    "- And we assume $0 \\log 0 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad0f55",
   "metadata": {},
   "source": [
    "#### 2.2 **Split Loss**\n",
    "\n",
    "Given a candidate split $\\theta$ applied at node $i$, the dataset $S_i$ is partitioned into a left subset $S_i^{\\text{left}}(\\theta)$ and a right subset $S_i^{\\text{right}}(\\theta)$:\n",
    "\n",
    "$$\n",
    "S_i^{\\text{left}}(\\theta) = \\{(x_j, y_j) \\in S_i \\mid x_{j, f} \\le t\\},\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_i^{\\text{right}}(\\theta) = S_i \\setminus S_i^{\\text{left}}(\\theta),\n",
    "$$\n",
    "\n",
    "where $\\theta = (f, t)$ denotes the split feature index $f$ and the threshold value $t$.\n",
    "\n",
    "Let the number of samples in the left and right subsets be\n",
    "\n",
    "$$\n",
    "N_i^{\\text{left}} = |S_i^{\\text{left}}(\\theta)|, \\qquad \n",
    "N_i^{\\text{right}} = |S_i^{\\text{right}}(\\theta)|.\n",
    "$$\n",
    "\n",
    "Their corresponding class proportions are computed in the same way as in Section 2.1.\n",
    "\n",
    "\n",
    "##### 2.2.1 **Weighted Child Impurity**\n",
    "\n",
    "Given an impurity function $C(\\cdot)$ (e.g., Gini or entropy), the **split loss** at node $i$ for candidate split $\\theta$ is defined as the weighted sum of the left and right child impurities:\n",
    "\n",
    "$$\n",
    "L(S_i, \\theta) \n",
    "= \n",
    "\\frac{N_i^{\\text{left}}}{N_i} \n",
    "\\, C\\!\\left(S_i^{\\text{left}}(\\theta)\\right)\n",
    "\\;+\\;\n",
    "\\frac{N_i^{\\text{right}}}{N_i}\n",
    "\\, C\\!\\left(S_i^{\\text{right}}(\\theta)\\right).\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $C\\!\\left(S_i^{\\text{left}}(\\theta)\\right)$ is the impurity (Gini or entropy) of the left child node.\n",
    "- $C\\!\\left(S_i^{\\text{right}}(\\theta)\\right)$ is the impurity of the right child node.\n",
    "\n",
    "\n",
    "##### 2.2.2 **Optimal Split Selection**\n",
    "\n",
    "The optimal split parameter is chosen by minimizing the split loss:\n",
    "\n",
    "$$\n",
    "\\theta^{*} = \\arg\\min_{\\theta} \\; L(S_i, \\theta).\n",
    "$$\n",
    "\n",
    "And this will be futher explained in the next part, Optimizer on how to actually implement it.\n",
    "\n",
    "- ***Reference***: scikit-learn mathematical formulation https://scikit-learn.org/stable/modules/tree.html#tree-mathematical-formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eed380",
   "metadata": {},
   "source": [
    "### 3. Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71bbe77",
   "metadata": {},
   "source": [
    "### 3.1 What is Optimized in CART\n",
    "\n",
    "CART performs a **greedy, recursive partitioning** - at each node, it selects the best split that maximizes information gain (or equivalently minimizes impurity).\n",
    "\n",
    "So the optimizer is essentially a **greedy search algorithm** that finds:\n",
    "\n",
    "$$\n",
    "\\arg\\min_{(f,t)} \\; \\text{Impurity}(S_{\\text{left}}) + \\text{Impurity}(S_{\\text{right}})\n",
    "$$\n",
    "\n",
    "where $f$ is the feature and $t$ is the threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d074bd",
   "metadata": {},
   "source": [
    "#### 3.1.1 Objective Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c847f",
   "metadata": {},
   "source": [
    "CART minimizes an **impurity measure** (loss function) such as:\n",
    "- Gini Index:\n",
    "$$ G(S) = 1 - \\sum_{k=1}^{K}p_k^2 $$\n",
    "- Entropy:\n",
    "$$ H(S) = - \\sum_{k=1}^{K}p_klog(p_k)$$\n",
    "\n",
    "At each node:\n",
    "$$\n",
    "\\text{Gain}(S, f, t) = \\text{Impurity}(S) \n",
    "- \\frac{|S_{\\text{left}}|}{|S|} \\, \\text{Impurity}(S_{\\text{left}}) \n",
    "- \\frac{|S_{\\text{right}}|}{|S|} \\, \\text{Impurity}(S_{\\text{right}})\n",
    "$$\n",
    "\n",
    "The algorithm chooses the feature $f*$ and threshold $t*$ that maximize this gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c31b7",
   "metadata": {},
   "source": [
    "#### 3.1.2 Pseudo-code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b0b67a",
   "metadata": {},
   "source": [
    "```python\n",
    "Inputs: dataset S, feature set F, impurity measure Impurity()\n",
    "\n",
    "best_gain ← 0  \n",
    "best_feature, best_threshold ← None  \n",
    "\n",
    "for each feature f in F:  \n",
    " for each possible threshold t in f:  \n",
    "  Split S into S_left and S_right using (f, t)  \n",
    "  if either split is empty: continue  \n",
    "  gain ← Impurity(S) \n",
    "     - (|S_left| / |S|) * Impurity(S_left)\n",
    "     - (|S_right| / |S|) * Impurity(S_right)  \n",
    "  if gain > best_gain:  \n",
    "   best_gain ← gain  \n",
    "   best_feature ← f  \n",
    "   best_threshold ← t  \n",
    "\n",
    "return (best_feature, best_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c447cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
